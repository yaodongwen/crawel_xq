from DrissionPage import ChromiumPage, ChromiumOptions
import time
import random
import json
import re
import threading
import os
from datetime import datetime
from tqdm import tqdm
import config
from db_manager import DBManager

try:
    import ollama
    HAS_OLLAMA = True
except ImportError:
    print(">>> è­¦å‘Š: æœªå®‰è£… ollama")
    HAS_OLLAMA = False

class XueqiuSpider:
    def __init__(self):
        print(">>> [ç³»ç»Ÿ] æ­£åœ¨æ¸…ç†æ®‹ç•™è¿›ç¨‹...")
        os.system("pkill -f 'Google Chrome'") 
        time.sleep(2) 

        print(">>> åˆå§‹åŒ–æ•°æ®åº“...")
        self.db = DBManager()
        self.seed_id = config.SEED_USER_URL.split('u/')[-1]
        
        self.existing_ids = self.db.get_existing_user_ids()
        self.target_ids_cache = self.db.get_existing_target_ids()
        
        print(">>> å¯åŠ¨æµè§ˆå™¨...")
        self.driver = self._init_browser()
        
        self.total_ai_saved = 0
        self.is_main_job_finished = False 

    def _init_browser(self):
        co = ChromiumOptions()
        co.set_browser_path(config.MAC_CHROME_PATH)
        co.set_user_data_path(config.USER_DATA_PATH)
        co.set_local_port(9337) 
        co.set_argument('--ignore-certificate-errors')
        try: return ChromiumPage(co)
        except Exception as e: 
            print(f"\n[å¯åŠ¨é”™è¯¯] {e}"); exit()

    # ================= å·¥å…·æ–¹æ³• =================
    
    def _get_now_str(self):
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _format_time(self, timestamp):
        try:
            # å…¼å®¹ Unix æ—¶é—´æˆ³
            if str(timestamp).isdigit():
                ts = float(timestamp) / 1000
                time_local = time.localtime(ts)
                return time.strftime("%Y-%m-%d %H:%M:%S", time_local)
            # å…¼å®¹å‚è€ƒä»£ç ä¸­çš„ datetime å­—ç¬¦ä¸²æ ¼å¼
            return str(timestamp)
        except: return str(timestamp)

    def random_sleep(self, min_s=1.0, max_s=2.0):
        time.sleep(random.uniform(min_s, max_s))

    def safe_action(self):
        self._check_405()
        max_retries = 10
        count = 0
        while self._has_slider():
            count += 1
            if count > 1: print(f">>> [æ»‘å—] ç¬¬ {count} æ¬¡å°è¯•...")
            self._solve_slider()
            time.sleep(2)
            if count >= max_retries:
                print(">>> [æ»‘å—] å°è¯•æ¬¡æ•°è¿‡å¤šï¼Œåˆ·æ–°é¡µé¢..."); 
                self.driver.latest_tab.refresh(); time.sleep(3); count=0

    def _has_slider(self):
        try:
            tab = self.driver.latest_tab
            return tab.ele('#aliyunCaptcha-sliding-slider', timeout=0.1) or tab.ele('text:è®¿é—®éªŒè¯', timeout=0.1)
        except: return False

    def _solve_slider(self):
        tab = self.driver.latest_tab
        time.sleep(1)
        try:
            btn = tab.ele('#aliyunCaptcha-sliding-slider', timeout=3)
            if btn: btn.drag(random.randint(400, 600), random.randint(5, 10))
        except: pass

    def _check_405(self):
        try:
            if "405" in self.driver.latest_tab.title:
                print("\n>>> [ä¸¥é‡] è§¦å‘405ï¼Œæš‚åœ15åˆ†é’Ÿ...")
                time.sleep(900)
                self.driver.latest_tab.refresh()
        except: pass
    
    def _restart_browser(self):
        try: self.driver.quit()
        except: pass
        os.system("pkill -f 'Google Chrome'")
        time.sleep(2)
        self.driver = self._init_browser()

    # ================= AI çº¿ç¨‹ =================
    
    def global_ai_worker(self):
        print(">>> [åå°AI] å¼•æ“å·²å¯åŠ¨ï¼Œè°ƒè¯•æ¨¡å¼å¼€å¯...")
        while True:
            raw_batch = self.db.get_unanalyzed_raw_data(limit=10)
            if not raw_batch:
                if self.is_main_job_finished: break
                time.sleep(2); continue

            for row in raw_batch:
                sid, content = row['Status_Id'], row['Description']
                clean = re.sub(r'<[^>]+>', '', content).strip().replace('\n', ' ')
                
                if len(clean) < 10: 
                    self.db.mark_raw_as_analyzed(sid, 1); continue

                prompt = f"""ä»»åŠ¡ï¼šåˆ¤æ–­è¿™æ¡è´¢ç»è¯„è®ºæ˜¯å¦æœ‰å«é‡‘é‡ã€‚
                è¯„è®ºå†…å®¹ï¼š"{clean}"
                è§„åˆ™ï¼š1. åŒ…å«å…·ä½“è‚¡ç¥¨åˆ†æã€é€»è¾‘ã€æ•°æ®ã€æ–°é—»è§£è¯» -> valuable: true
                2. çº¯æƒ…ç»ªå‘æ³„ã€æ‰“å¡ã€æ— æ„ä¹‰æ°´è´´ -> valuable: false
                å¿…é¡»è¿”å›JSONæ ¼å¼ï¼š{{"valuable": true/false, "cat": "åˆ†ç±»æ ‡ç­¾"}}"""
                
                try:
                    res = ollama.chat(
                        model=config.AI_MODEL_NAME, 
                        messages=[{'role':'user','content':prompt}],
                        format='json', options={"temperature": 0.1}
                    )
                    js = json.loads(res['message']['content'])
                    valuable = js.get('valuable', False)
                    cat = js.get('cat', 'å…¶ä»–')
                    
                    final_cat = cat if valuable else f"[ä½ä»·å€¼]-{cat}"
                    self.db.execute_one_safe(
                        "INSERT OR IGNORE INTO Value_Comments VALUES (?,?,?,?,?,?)",
                        (sid, row['User_Id'], row['Description'], row['Created_At'], row['Stock_Tags'], final_cat)
                    )
                    
                    if valuable:
                        print(f"    [AI] ğŸŸ¢ æ”¶å½• | {cat} | {clean[:15]}...")
                        self.total_ai_saved += 1
                    else:
                        print(f"    [AI] âšª ä¸¢å¼ƒ | {cat} | {clean[:15]}...", end='\r')
                    self.db.mark_raw_as_analyzed(sid, 1)
                except Exception as e:
                    self.db.mark_raw_as_analyzed(sid, 2)

    # ================= Step 1: æ‰¹æ¬¡æ‰«æ =================

    def step1_batch_scan(self):
        pending_hq = len(self.db.get_pending_tasks("High_quality_users", limit=config.PIPELINE_BATCH_SIZE * 5))
        if pending_hq >= config.PIPELINE_BATCH_SIZE * 5: return

        current_users_count = self.db.get_total_users_count()
        if current_users_count >= config.FOCUS_COUNT_LIMIT: return

        print(f"\n=== Step 1: å¯»æ‰¾æ–°ç”¨æˆ· (ç›®æ ‡æ–°å¢: {config.PIPELINE_BATCH_SIZE} äºº) ===")
        if self.db.is_user_scanned(self.seed_id): current_source_id = None
        else: current_source_id = self.seed_id
        
        if not current_source_id:
            next_user = self.db.get_next_source_user()
            if not next_user: print(">>> æ— å¯ç”¨å®¿ä¸»"); return
            current_source_id = next_user['User_Id']
            print(f">>> åˆ‡æ¢å®¿ä¸»: {next_user['User_Name']}")
        else: print(f">>> ç»§ç»­å®¿ä¸»: {current_source_id}")

        tab = self.driver.latest_tab
        new_hq_added_in_this_batch = 0
        
        try:
            tab.get(f"https://xueqiu.com/u/{current_source_id}")
            time.sleep(2)
            if "follow" not in tab.url:
                btn = tab.ele('tag:a@@href=#/follow', timeout=3)
                if btn: btn.click()
                else: 
                    self.db.mark_user_as_scanned(current_source_id); return
            
            tab.listen.start(config.API['FOCUS'])
            page_count = 0
            
            while True:
                self.safe_action()
                if new_hq_added_in_this_batch >= config.PIPELINE_BATCH_SIZE: break 

                next_btn = tab.ele('.pagination__next', timeout=3)
                if not next_btn or not next_btn.states.is_displayed: 
                    self.db.mark_user_as_scanned(current_source_id); break
                
                next_btn.click(by_js=True)
                self.random_sleep()
                
                res = tab.listen.wait(timeout=6)
                if res and 'users' in res.response.body:
                    users = res.response.body['users']
                    new_users = []
                    new_hq = []
                    now_str = self._get_now_str()

                    for u in users:
                        uid = u.get('id')
                        if uid in self.existing_ids: continue
                        self.existing_ids.add(uid)
                        
                        row = (uid, u.get('screen_name'), u.get('status_count', 0),
                               u.get('friends_count', 0), u.get('followers_count', 0), 
                               u.get('description', ''), now_str) 
                        new_users.append(row)
                        
                        if int(u.get('followers_count', 0)) > 5000: 
                            hq_row = list(row); hq_row[-1] = None 
                            new_hq.append(tuple(hq_row))
                            new_hq_added_in_this_batch += 1
                    
                    if new_users: self.db.execute_many_safe("INSERT OR IGNORE INTO users VALUES (?,?,?,?,?,?,?)", new_users)
                    if new_hq: self.db.execute_many_safe("INSERT OR IGNORE INTO High_quality_users VALUES (?,?,?,?,?,?,?)", new_hq)
                    print(f"    [æ‰«æ] æœ¬è½®æ–°å¢ä¼˜è´¨: {new_hq_added_in_this_batch}/{config.PIPELINE_BATCH_SIZE}", end='\r')

                page_count += 1
                if page_count > 20: break 
            tab.listen.stop()
        except Exception as e: pass

    # ================= Step 2: æ‰¹æ¬¡ç­›é€‰ =================

    def step2_batch_filter(self):
        pending = self.db.get_pending_tasks("High_quality_users", limit=config.PIPELINE_BATCH_SIZE)
        if not pending: return

        print(f"\n=== Step 2: ç­›é€‰æŒä»“ (æ‰¹æ¬¡: {len(pending)} äºº) ===")
        tab = self.driver.latest_tab
        
        for row in pending:
            uid, uname = row['User_Id'], row['User_Name']
            ai_left = self.db.get_unanalyzed_count()
            print(f"    Check: {uname} | AIå¾…åŠ: {ai_left}", end='\r')

            if uid in self.target_ids_cache:
                self.db.update_task_status(uid, "High_quality_users"); continue
            
            self.safe_action()
            try:
                tab.get(f"https://xueqiu.com/u/{uid}")
                self.random_sleep(1.5, 2.0)
                tab.listen.start(config.API['STOCK'])
                
                stock_btn = tab.ele('tag:a@@href=#/stock', timeout=4)
                if stock_btn:
                    stock_btn.click()
                    end_time = time.time() + 4
                    has_agu = False; has_waipan = False; now_str = self._get_now_str()
                    
                    while time.time() < end_time:
                        res = tab.listen.wait(timeout=1.0)
                        if not res: continue
                        data = res.response.body
                        if not data: continue

                        if 'net_value' in str(data): # ç»„åˆ
                            comb_list = []
                            iterator = data.values() if isinstance(data, dict) else data
                            for item in iterator:
                                if not isinstance(item, dict) or 'symbol' not in item: continue
                                comb_list.append((uid, item.get('symbol'), item.get('name'), float(item.get('net_value',0) or 0), str(item.get('total_gain',0)), str(item.get('monthly_gain',0)), str(item.get('daily_gain',0)), now_str))
                            if comb_list: self.db.execute_many_safe("INSERT OR REPLACE INTO User_Combinations (User_Id, Symbol, Name, Net_Value, Total_Gain, Monthly_Gain, Daily_Gain, Updated_At) VALUES (?,?,?,?,?,?,?,?)", comb_list)

                        else: # è‡ªé€‰è‚¡
                            items = []
                            if isinstance(data, dict):
                                if 'data' in data and 'items' in data['data']: items = data['data']['items']
                                elif 'items' in data: items = data['items']
                            if items:
                                stock_list = []
                                for it in items:
                                    s = it.get('quote', it)
                                    symbol = s.get('symbol') or s.get('code', '')
                                    if not symbol: continue
                                    market = 'æœªçŸ¥'
                                    if symbol.startswith('SH') or symbol.startswith('SZ'): market = 'CN'; has_agu = True
                                    elif len(symbol)==5 and symbol.isdigit(): market = 'HK'; has_waipan = True
                                    elif '.' not in symbol and len(symbol)<5: market = 'US'; has_waipan = True
                                    stock_list.append((uid, s.get('name',''), symbol, float(s.get('current',0) or 0), float(s.get('percent',0) or 0), market, now_str))
                                if stock_list: self.db.execute_many_safe("INSERT OR REPLACE INTO User_Stocks (User_Id, Stock_Name, Stock_Symbol, Current_Price, Percent, Market, Updated_At) VALUES (?,?,?,?,?,?,?)", stock_list)

                    if has_agu and has_waipan:
                        target_data = list(row); target_data[-1] = None # Step 3 å¾…åŠ
                        self.db.execute_one_safe("INSERT OR IGNORE INTO Target_users VALUES (?,?,?,?,?,?,?)", tuple(target_data))
                        self.target_ids_cache.add(uid)
                    tab.listen.stop()
                
                self.db.update_task_status(uid, "High_quality_users")
            except: pass

    # ================= Step 3: æ‰¹æ¬¡çˆ¬å– (å«é•¿æ–‡é€»è¾‘) =================

    def _mine_long_articles(self, tab, uid):
        """ã€æ–°å¢ã€‘ä¸“é—¨æŒ–æ˜é•¿æ–‡ï¼Œè·å–å®Œæ•´å†…å®¹"""
        try:
            # 1. å°è¯•ç‚¹å‡»â€œé•¿æ–‡â€æ ‡ç­¾
            # ä½¿ç”¨ contains æ¨¡ç³ŠåŒ¹é…é˜²æ­¢é¡µé¢å¾®è°ƒ
            long_tab = tab.ele('xpath://a[contains(text(), "é•¿æ–‡")]', timeout=2)
            if not long_tab: return 0
            
            long_tab.click()
            self.random_sleep(1.5, 2.5)
            
            # 2. è·å–å½“å‰é¡µé¢æ‰€æœ‰é•¿æ–‡å¡ç‰‡
            # å‚è€ƒä»£ç ä½¿ç”¨çš„ class é€‰æ‹©å™¨
            articles = tab.eles('.timeline__item__content timeline__item__content--longtext', timeout=3)
            if not articles: return 0
            
            count = 0
            # é™åˆ¶æ¯æ¬¡åªçˆ¬å‰ 5 ç¯‡é•¿æ–‡ï¼Œé¿å…å¤ªæ…¢
            for article_ele in articles[:5]:
                try:
                    # ç‚¹å‡»è¿›å…¥é•¿æ–‡è¯¦æƒ…é¡µ (è¿™ä¼šæ‰“å¼€æ–°æ ‡ç­¾æˆ–åœ¨å½“å‰é¡µè·³è½¬ï¼ŒDrissionPage ä¼šè‡ªåŠ¨å¤„ç†æ–° Tab)
                    article_ele.click()
                    time.sleep(2)
                    
                    # è·å–æœ€æ–°æ ‡ç­¾é¡µï¼ˆå³æ–‡ç« è¯¦æƒ…é¡µï¼‰
                    detail_tab = self.driver.latest_tab
                    
                    # === æŠ“å–é€»è¾‘ ===
                    current_url = detail_tab.url
                    # æå– ID: https://xueqiu.com/12345/67890 -> status_id = 67890
                    parts = current_url.split('/')
                    if len(parts) >= 5:
                        comment_id = parts[-1]
                        
                        # è·å–æ—¶é—´
                        pub_time = ""
                        time_ele = detail_tab.ele('xpath://div[@class="avatar__subtitle"]/a/time', timeout=2)
                        if time_ele:
                            # å¯èƒ½æ˜¯ text æˆ– datetime å±æ€§
                            pub_time = time_ele.attr('datetime') or time_ele.text
                            pub_time = self._format_time(pub_time)

                        # è·å–å…¨é‡å†…å®¹ (æ ‡é¢˜ + æ­£æ–‡)
                        title_ele = detail_tab.ele('.article__bd__title', timeout=2)
                        content_ele = detail_tab.ele('.article__bd__detail', timeout=2)
                        
                        full_text = ""
                        if title_ele: full_text += f"ã€é•¿æ–‡æ ‡é¢˜ã€‘{title_ele.text}\n"
                        if content_ele: full_text += f"{content_ele.text}"
                        
                        if full_text and comment_id.isdigit():
                            # === å…¥åº“ ===
                            # ä½¿ç”¨ REPLACEï¼Œå¦‚æœä¹‹å‰ JSON æŠ“åˆ°è¿‡æˆªæ–­ç‰ˆï¼Œè¿™é‡Œä¼šç”¨å®Œæ•´ç‰ˆè¦†ç›–
                            self.db.execute_one_safe(
                                "INSERT OR REPLACE INTO Raw_Statuses (Status_Id, User_Id, Description, Created_At, Stock_Tags, Is_Analyzed) VALUES (?,?,?,?,?,?)",
                                (comment_id, uid, full_text, pub_time, "LongArticle", 0) # é‡ç½®ä¸º 0 è®© AI é‡æ–°åˆ†æ
                            )
                            count += 1
                            print(f"    --> [é•¿æ–‡] è·å–æˆåŠŸ: {comment_id} (å­—æ•°: {len(full_text)})")

                    # å…³é—­è¯¦æƒ…é¡µï¼Œåˆ‡å›åˆ—è¡¨é¡µ
                    detail_tab.close()
                    time.sleep(1)
                    
                except Exception as e:
                    # print(f"é•¿æ–‡æŠ“å–å•æ¡å¤±è´¥: {e}")
                    # å¦‚æœå‡ºé”™äº†ï¼Œç¡®ä¿æŠŠå¯èƒ½æ‰“å¼€çš„æ ‡ç­¾é¡µå…³æ‰
                    if self.driver.tabs_count > 1:
                        self.driver.latest_tab.close()
            
            return count

        except Exception as e:
            # print(f"é•¿æ–‡æ¨¡å—å¼‚å¸¸: {e}")
            return 0

    def step3_batch_mine(self):
        pending = self.db.get_pending_tasks("Target_users", limit=config.PIPELINE_BATCH_SIZE)
        if not pending: return

        print(f"\n=== Step 3: çˆ¬å–è¯„è®º (æ‰¹æ¬¡: {len(pending)} äºº) ===")
        tab = self.driver.latest_tab
        
        for row in pending:
            uid, uname = row['User_Id'], row['User_Name']
            ai_left = self.db.get_unanalyzed_count()
            print(f"    User: {uname} | AIå¾…åŠ: {ai_left}")
            
            self.safe_action()
            try:
                # === é˜¶æ®µ 1: å¿«é€ŸæŠ“å– JSON (çŸ­è´´ + åŠ¨æ€) ===
                target_api = 'user_timeline.json'
                tab.listen.start(target_api)
                
                tab.get(f"https://xueqiu.com/u/{uid}")
                
                # ç­‰å¾…ç¬¬ä¸€é¡µ JSON
                res = tab.listen.wait(timeout=5)
                
                total_added = 0 
                if res and res.response.body and 'statuses' in res.response.body:
                    raw_rows = []
                    for s in res.response.body['statuses']:
                        readable_time = self._format_time(s['created_at'])
                        raw_rows.append((s['id'], s['user_id'], s['description'], readable_time, str(s.get('stockCorrelation','')), 0))
                    if raw_rows:
                        self.db.execute_many_safe("INSERT OR IGNORE INTO Raw_Statuses (Status_Id, User_Id, Description, Created_At, Stock_Tags, Is_Analyzed) VALUES (?,?,?,?,?,?)", raw_rows)
                        total_added += len(raw_rows)
                else:
                     if not res: print(f"    âš ï¸ ç¬¬ä¸€é¡µè¶…æ—¶")

                # ç®€å•ç¿»ä¸¤é¡µ (è·å–æ›´å¤šçŸ­è´´)
                for p in range(2): 
                    if self._has_slider(): self.safe_action()
                    next_btn = tab.ele('.pagination__next', timeout=2)
                    if next_btn and next_btn.states.is_displayed: 
                        next_btn.click(by_js=True)
                        res = tab.listen.wait(timeout=5)
                        if res and res.response.body and 'statuses' in res.response.body:
                            raw_rows = []
                            for s in res.response.body['statuses']:
                                readable_time = self._format_time(s['created_at'])
                                raw_rows.append((s['id'], s['user_id'], s['description'], readable_time, str(s.get('stockCorrelation','')), 0))
                            if raw_rows:
                                self.db.execute_many_safe("INSERT OR IGNORE INTO Raw_Statuses (Status_Id, User_Id, Description, Created_At, Stock_Tags, Is_Analyzed) VALUES (?,?,?,?,?,?)", raw_rows)
                                total_added += len(raw_rows)
                    else: break
                
                tab.listen.stop()

                # === é˜¶æ®µ 2: æ·±åº¦æŠ“å–é•¿æ–‡ (è·å–å®Œæ•´é€»è¾‘) ===
                # è¿™é‡Œè°ƒç”¨æ–°å¢çš„æ–¹æ³•
                long_count = self._mine_long_articles(tab, uid)
                
                print(f"    -> å®Œæˆ: {uname} (çŸ­è´´: {total_added}, é•¿æ–‡è¡¥å…¨: {long_count})")
                self.db.update_task_status(uid, "Target_users")
                
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸ [{uname}]: {e}")
                if "æ–­å¼€" in str(e) or "disconnected" in str(e): 
                    self._restart_browser(); tab = self.driver.latest_tab
                else: tab.listen.stop()

    def run(self):
        print(">>> å¯åŠ¨...")
        ai_thread = threading.Thread(target=self.global_ai_worker, daemon=True)
        ai_thread.start()
        
        self.driver.get("https://xueqiu.com")
        print("\n" + "="*50); input(">>> è¯·æ‰«ç ç™»å½•ï¼Œå®ŒæˆåæŒ‰ã€å›è½¦ã€‘..."); print("="*50 + "\n")
        
        try:
            while True:
                current_targets = self.db.get_target_count()
                if current_targets >= config.TARGET_GOAL:
                    print("\n>>> ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼ç›®æ ‡ç”¨æˆ·æ”¶é›†å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰"); break 
                
                current_users = self.db.get_total_users_count()
                ai_backlog = self.db.get_unanalyzed_count()
                print(f"\n>>> [å¾ªç¯] ç›®æ ‡:{current_targets}/{config.TARGET_GOAL} | ç”¨æˆ·åº“:{current_users}/{config.FOCUS_COUNT_LIMIT} | AIç§¯å‹:{ai_backlog}")
                
                self.step3_batch_mine()   
                self.step2_batch_filter() 
                self.step1_batch_scan()   
                time.sleep(2)

        except KeyboardInterrupt: print("\n\n>>> ğŸ›‘ æ£€æµ‹åˆ°ç”¨æˆ·ä¸­æ–­ (Ctrl+C)...")
        except Exception as e: print(f"\n\n>>> âŒ å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
        finally:
            self.is_main_job_finished = True
            left = self.db.get_unanalyzed_count()
            if left > 0: print(f">>> æç¤º: AI çº¿ç¨‹è¿˜åœ¨å¤„ç†å‰©ä½™çš„ {left} æ¡æ•°æ®...")

if __name__ == '__main__':
    bot = XueqiuSpider()
    bot.run()