from DrissionPage import ChromiumPage, ChromiumOptions
import time
import random
import gzip
import json
import re
import threading
import os
from datetime import datetime
from tqdm import tqdm
import config
from db_manager import DBManager

try:
    import ollama
    HAS_OLLAMA = True
except ImportError:
    print(">>> è­¦å‘Š: æœªå®‰è£… ollama")
    HAS_OLLAMA = False

class XueqiuSpider:
    def __init__(self):
        print(">>> [ç³»ç»Ÿ] æ­£åœ¨æ¸…ç†æ®‹ç•™è¿›ç¨‹...")
        os.system("pkill -f 'Google Chrome'") 
        time.sleep(2) 

        print(">>> åˆå§‹åŒ–æ•°æ®åº“...")
        self.db = DBManager()
        self.seed_id = config.SEED_USER_URL.split('u/')[-1]
        
        self.existing_ids = self.db.get_existing_user_ids()
        self.target_ids_cache = self.db.get_existing_target_ids()
        
        print(">>> å¯åŠ¨æµè§ˆå™¨...")
        self.driver = self._init_browser()
        
        self.total_ai_saved = 0
        self.is_main_job_finished = False 

    def _init_browser(self):
        co = ChromiumOptions()
        co.set_browser_path(config.MAC_CHROME_PATH)
        co.set_user_data_path(config.USER_DATA_PATH)
        co.set_local_port(9337) 
        co.set_argument('--ignore-certificate-errors')
        try: return ChromiumPage(co)
        except Exception as e: 
            print(f"\n[å¯åŠ¨é”™è¯¯] {e}"); exit()

    # ================= å·¥å…·æ–¹æ³• =================
    
    def _get_now_str(self):
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _format_time(self, timestamp):
        try:
            # å…¼å®¹ Unix æ—¶é—´æˆ³
            if str(timestamp).isdigit():
                ts = float(timestamp) / 1000
                time_local = time.localtime(ts)
                return time.strftime("%Y-%m-%d %H:%M:%S", time_local)
            # å…¼å®¹å‚è€ƒä»£ç ä¸­çš„ datetime å­—ç¬¦ä¸²æ ¼å¼
            return str(timestamp)
        except: return str(timestamp)

    def random_sleep(self, min_s=1.0, max_s=2.0):
        time.sleep(random.uniform(min_s, max_s))

    def safe_action(self):
        self._check_405()
        max_retries = 10
        count = 0
        while self._has_slider():
            count += 1
            if count > 1: print(f">>> [æ»‘å—] ç¬¬ {count} æ¬¡å°è¯•...")
            self._solve_slider()
            time.sleep(2)
            if count >= max_retries:
                print(">>> [æ»‘å—] å°è¯•æ¬¡æ•°è¿‡å¤šï¼Œåˆ·æ–°é¡µé¢..."); 
                self.driver.latest_tab.refresh(); time.sleep(3); count=0

    def _has_slider(self):
        try:
            tab = self.driver.latest_tab
            return tab.ele('#aliyunCaptcha-sliding-slider', timeout=0.1) or tab.ele('text:è®¿é—®éªŒè¯', timeout=0.1)
        except: return False

    def _solve_slider(self):
        tab = self.driver.latest_tab
        time.sleep(1)
        try:
            btn = tab.ele('#aliyunCaptcha-sliding-slider', timeout=3)
            if btn: btn.drag(random.randint(400, 600), random.randint(5, 10))
        except: pass

    def _check_405(self):
        try:
            if "405" in self.driver.latest_tab.title:
                print("\n>>> [ä¸¥é‡] è§¦å‘405ï¼Œæš‚åœ15åˆ†é’Ÿ...")
                time.sleep(900)
                self.driver.latest_tab.refresh()
        except: pass
    
    def _restart_browser(self):
        try: self.driver.quit()
        except: pass
        os.system("pkill -f 'Google Chrome'")
        time.sleep(2)
        self.driver = self._init_browser()

    # ================= AI çº¿ç¨‹ =================
    
    def global_ai_worker(self):
        # === ã€æ–°å¢ã€‘å¯åŠ¨æ—¶ä¸»åŠ¨æ¢æµ‹ Ollama æ˜¯å¦å¯ç”¨ ===
        if HAS_OLLAMA:
            try:
                models = ollama.list()
                model_names = [m['model'] for m in models.get('models', [])]
                if config.AI_MODEL_NAME not in model_names:
                    print(f"âš ï¸ è­¦å‘Š: æŒ‡å®šæ¨¡å‹ '{config.AI_MODEL_NAME}' æœªå®‰è£…ï¼")
                    print(f"   å¯ç”¨æ¨¡å‹: {model_names[:5]}{'...' if len(model_names)>5 else ''}")
                else:
                    print(f"âœ… Ollama æœåŠ¡æ­£å¸¸ï¼Œä½¿ç”¨æ¨¡å‹: {config.AI_MODEL_NAME}")
            except Exception as e:
                print(f"âŒ Ollama æœåŠ¡ä¸å¯ç”¨ (å¯èƒ½æœªå¯åŠ¨): {e}")
                print("   è¯·ç¡®ä¿è¿è¡Œ: ollama serve")
        else:
            print("âŒ Ollama æœªå®‰è£…ï¼ŒAI åŠŸèƒ½å°†è·³è¿‡æ‰€æœ‰å†…å®¹")

        print(">>> [åå°AI] å¼•æ“å·²å¯åŠ¨ï¼Œè°ƒè¯•æ¨¡å¼å¼€å¯...")
        while True:
            raw_batch = self.db.get_unanalyzed_raw_data(limit=10)
            if not raw_batch:
                if self.is_main_job_finished: break
                time.sleep(2); continue

            for row in raw_batch:
                sid, content = row['Status_Id'], row['Description']
                clean = re.sub(r'<[^>]+>', '', content).strip().replace('\n', ' ')
                
                if len(clean) < 10: 
                    self.db.mark_raw_as_analyzed(sid, 1); continue

                prompt = f"""ä»»åŠ¡ï¼šåˆ¤æ–­è¿™æ¡è´¢ç»è¯„è®ºæ˜¯å¦æœ‰å«é‡‘é‡ã€‚
                è¯„è®ºå†…å®¹ï¼š"{clean}"
                è§„åˆ™ï¼š1. å¦‚æœåŒ…å«å…·ä½“è‚¡ç¥¨åˆ†æã€é€»è¾‘ã€æ•°æ®ã€æ–°é—»è§£è¯»ç­‰èƒ½æœ‰åŠ©äºåˆ¤æ–­è‚¡ç¥¨æ¶¨åŠ¿çš„ä¿¡æ¯ï¼Œåˆ™valuableå­—æ®µä¸ºtrueã€‚åä¹‹ï¼Œå¦‚æœå…¨éƒ½åœ¨è®¨è®ºå’Œè‚¡ç¥¨ã€è¡Œä¸šæ— å…³å†…å®¹ï¼Œåˆ™valuableä¸ºfalseã€‚
                2. å¦‚æœè¯„è®ºé‡Œé¢æœ‰è‚¡ç¥¨,åˆ™åœ¨catä¸­è¾“å‡ºè‚¡ç¥¨çš„ç±»åˆ«ï¼Œæ¯”å¦‚:Aè‚¡ï¼Œç¾è‚¡ï¼Œæ¸¯è‚¡ï¼Œæ—¥è‚¡ï¼ŒéŸ©è‚¡ï¼Œå¾·è‚¡ç­‰ã€‚å¦åˆ™è¾“å‡ºå…¶ä»–ã€‚
                å¿…é¡»è¿”å›JSONæ ¼å¼ï¼š{{"valuable": true/false, "cat": "è‚¡ç¥¨ç±»åˆ«"}}"""
                
                try:
                    res = ollama.chat(
                        model=config.AI_MODEL_NAME, 
                        messages=[{'role':'user','content':prompt}],
                        format='json', options={
                            "temperature": 0.1,      # æ›´ç¡®å®šæ€§
                            "num_predict": 30,       # ä¸¥æ ¼é™åˆ¶è¾“å‡ºé•¿åº¦
                            "top_k": 15,
                            "top_p": 0.85
                        }
                    )
                    js = json.loads(res['message']['content'])
                    valuable = js.get('valuable', False)
                    cat = js.get('cat', 'å…¶ä»–')
                    
                    final_cat = cat if valuable else f"[ä½ä»·å€¼]-{cat}"
                    self.db.execute_one_safe(
                        "INSERT OR IGNORE INTO Value_Comments VALUES (?,?,?,?,?,?,?,?,?)",
                        (sid, row['User_Id'], row['Description'], row['Created_At'], row['Stock_Tags'],
                        final_cat,row['Forward'],row['Comment_Count'],row['Like'])
                    )
                    
                    if valuable:
                        print(f"    [AI] ğŸŸ¢ æ”¶å½• | {cat} | {clean[:15]}...")
                        self.total_ai_saved += 1
                    else:
                        print(f"    [AI] âšª ä¸¢å¼ƒ | {cat} | {clean[:15]}...", end='\r')
                    self.db.mark_raw_as_analyzed(sid, 1)
                except Exception as e:
                    print(f"error in AI: {e}")
                    self.db.mark_raw_as_analyzed(sid, 2)

    # ================= Step 1: æ‰¹æ¬¡æ‰«æ =================

    def step1_batch_scan(self):
        pending_hq = len(self.db.get_pending_tasks("High_quality_users", limit=config.PIPELINE_BATCH_SIZE * 5))
        if pending_hq >= config.PIPELINE_BATCH_SIZE * 5: return

        current_users_count = self.db.get_total_users_count()
        if current_users_count >= config.FOCUS_COUNT_LIMIT: return

        print(f"\n=== Step 1: å¯»æ‰¾æ–°ç”¨æˆ· (ç›®æ ‡æ–°å¢: {config.PIPELINE_BATCH_SIZE} äºº) ===")
        if self.db.is_user_scanned(self.seed_id): current_source_id = None
        else: current_source_id = self.seed_id
        
        if not current_source_id:
            next_user = self.db.get_next_source_user()
            if not next_user: print(">>> æ— å¯ç”¨å®¿ä¸»"); return
            current_source_id = next_user['User_Id']
            print(f">>> åˆ‡æ¢å®¿ä¸»: {next_user['User_Name']}")
        else: print(f">>> ç»§ç»­å®¿ä¸»: {current_source_id}")

        tab = self.driver.latest_tab
        new_hq_added_in_this_batch = 0
        
        try:
            tab.get(f"https://xueqiu.com/u/{current_source_id}")
            time.sleep(2)
            if "follow" not in tab.url:
                btn = tab.ele('tag:a@@href=#/follow', timeout=3)
                if btn: btn.click()
                else: 
                    self.db.mark_user_as_scanned(current_source_id); return
            
            tab.listen.start(config.API['FOCUS'])
            page_count = 0
            
            while True:
                self.safe_action()
                if new_hq_added_in_this_batch >= config.PIPELINE_BATCH_SIZE: break 

                next_btn = tab.ele('.pagination__next', timeout=3)
                if not next_btn or not next_btn.states.is_displayed: 
                    self.db.mark_user_as_scanned(current_source_id); break
                
                next_btn.click(by_js=True)
                self.random_sleep()
                
                res = tab.listen.wait(timeout=6)
                if res and 'users' in res.response.body:
                    users = res.response.body['users']
                    new_users = []
                    new_hq = []
                    now_str = self._get_now_str()

                    for u in users:
                        uid = u.get('id')
                        if uid in self.existing_ids: continue
                        self.existing_ids.add(uid)
                        
                        row = (uid, u.get('screen_name'), u.get('status_count', 0),
                               u.get('friends_count', 0), u.get('followers_count', 0), 
                               u.get('text', ''), now_str) 
                        new_users.append(row)
                        
                        if int(u.get('followers_count', 0)) > 5000: 
                            hq_row = list(row); hq_row[-1] = None 
                            new_hq.append(tuple(hq_row))
                            new_hq_added_in_this_batch += 1
                    
                    if new_users: self.db.execute_many_safe("INSERT OR IGNORE INTO users VALUES (?,?,?,?,?,?,?)", new_users)
                    if new_hq: self.db.execute_many_safe("INSERT OR IGNORE INTO High_quality_users VALUES (?,?,?,?,?,?,?)", new_hq)
                    print(f"    [æ‰«æ] æœ¬è½®æ–°å¢ä¼˜è´¨: {new_hq_added_in_this_batch}/{config.PIPELINE_BATCH_SIZE}", end='\r')

                page_count += 1
                if page_count > 20: break 
            tab.listen.stop()
        except Exception as e: pass

    # ================= Step 2: æ‰¹æ¬¡ç­›é€‰ =================

    def step2_batch_filter(self):
        pending = self.db.get_pending_tasks("High_quality_users", limit=config.PIPELINE_BATCH_SIZE)
        if not pending: return

        print(f"\n=== Step 2: ç­›é€‰æŒä»“ (æ‰¹æ¬¡: {len(pending)} äºº) ===")
        tab = self.driver.latest_tab
        
        for row in pending:
            uid, uname = row['User_Id'], row['User_Name']
            ai_left = self.db.get_unanalyzed_count()
            print(f"    Check: {uname} | AIå¾…åŠ: {ai_left}", end='\r')

            if uid in self.target_ids_cache:
                self.db.update_task_status(uid, "High_quality_users"); continue
            
            self.safe_action()
            try:
                tab.get(f"https://xueqiu.com/u/{uid}")
                self.random_sleep(1.5, 2.0)
                tab.listen.start(config.API['STOCK'])
                
                stock_btn = tab.ele('tag:a@@href=#/stock', timeout=4)
                if stock_btn:
                    stock_btn.click()
                    end_time = time.time() + 4
                    has_agu = False; has_waipan = False; now_str = self._get_now_str()
                    
                    while time.time() < end_time:
                        res = tab.listen.wait(timeout=1.0)
                        if not res: continue
                        data = res.response.body
                        if not data: continue

                        if 'net_value' in str(data): # ç»„åˆ
                            comb_list = []
                            iterator = data.values() if isinstance(data, dict) else data
                            for item in iterator:
                                if not isinstance(item, dict) or 'symbol' not in item: continue
                                comb_list.append((uid, item.get('symbol'), item.get('name'), float(item.get('net_value',0) or 0), str(item.get('total_gain',0)), str(item.get('monthly_gain',0)), str(item.get('daily_gain',0)), now_str, str(item.get('closed_at',0))))
                            if comb_list: self.db.execute_many_safe("INSERT OR REPLACE INTO User_Combinations (User_Id, Symbol, Name, Net_Value, Total_Gain, Monthly_Gain, Daily_Gain, Updated_At, Close_At_Time) VALUES (?,?,?,?,?,?,?,?,?)", comb_list)

                        else: # è‡ªé€‰è‚¡
                            items = []
                            if isinstance(data, dict):
                                if 'data' in data and 'items' in data['data']: items = data['data']['items']
                                elif 'items' in data: items = data['items']
                            if items:
                                stock_list = []
                                for it in items:
                                    s = it.get('quote', it)
                                    symbol = s.get('symbol') or s.get('code', '')
                                    if not symbol: continue
                                    market = 'æœªçŸ¥'
                                    if symbol.startswith('SH') or symbol.startswith('SZ'): market = 'CN'; has_agu = True
                                    elif len(symbol)==5 and symbol.isdigit(): market = 'HK'; has_waipan = True
                                    elif '.' not in symbol and len(symbol)<5: market = 'US'; has_waipan = True
                                    stock_list.append((uid, s.get('name',''), symbol, float(s.get('current',0) or 0), float(s.get('percent',0) or 0), market, now_str))
                                if stock_list: self.db.execute_many_safe("INSERT OR REPLACE INTO User_Stocks (User_Id, Stock_Name, Stock_Symbol, Current_Price, Percent, Market, Updated_At) VALUES (?,?,?,?,?,?,?)", stock_list)

                    if has_agu and has_waipan:
                        target_data = list(row); target_data[-1] = None # Step 3 å¾…åŠ
                        self.db.execute_one_safe("INSERT OR IGNORE INTO Target_users VALUES (?,?,?,?,?,?,?)", tuple(target_data))
                        self.target_ids_cache.add(uid)
                    tab.listen.stop()
                
                self.db.update_task_status(uid, "High_quality_users")
            except: pass

    # ================= Step 3: æ‰¹æ¬¡çˆ¬å– (å«é•¿æ–‡é€»è¾‘) =================

    def _mine_long_articles(self, uid, status_id):
        """
        ã€ä¿®æ”¹ç‰ˆã€‘é•¿æ–‡è·å–é€»è¾‘ï¼š
        ç›´æ¥æ–°å»ºæ ‡ç­¾é¡µè®¿é—®é•¿æ–‡ URL (https://xueqiu.com/uid/id)ï¼Œ
        æŠ“å–å®Œæ•´æ ‡é¢˜å’Œæ­£æ–‡åè¿”å›ã€‚
        """
        try:
            # æ„é€ é•¿æ–‡é“¾æ¥
            url = f"https://xueqiu.com/{uid}/{status_id}"
            
            # æ‰“å¼€æ–°æ ‡ç­¾é¡µ (DrissionPage ä¼šè‡ªåŠ¨åˆ‡æ¢ç„¦ç‚¹åˆ°æ–°é¡µé¢)
            detail_tab = self.driver.new_tab(url)
            
            # ç­‰å¾…æ ¸å¿ƒå…ƒç´ åŠ è½½ (æ ‡é¢˜æˆ–æ­£æ–‡)
            # ç»™ 5 ç§’è¶…æ—¶ï¼Œé˜²æ­¢é¡µé¢åŠ è½½å¤ªæ…¢å¡ä½
            title_ele = detail_tab.ele('.article__bd__title', timeout=5)
            content_ele = detail_tab.ele('.article__bd__detail', timeout=5)
            
            full_text = ""
            if title_ele: 
                full_text += f"ã€é•¿æ–‡æ ‡é¢˜ã€‘{title_ele.text}\n"
            if content_ele: 
                full_text += f"{content_ele.text}"
            
            # æŠ“å–å®Œæˆåå…³é—­å½“å‰é•¿æ–‡é¡µ
            detail_tab.close()
            
            # å¦‚æœæ²¡æŠ“åˆ°å†…å®¹ï¼Œè¿”å› None
            if not full_text:
                return None
            
            # print(f"    --> [è¡¥å…¨æˆåŠŸ] é•¿æ–‡ {status_id} ({len(full_text)}å­—)")   
            return full_text

        except Exception as e:
            # print(f"    âš ï¸ é•¿æ–‡è¡¥å…¨å¤±è´¥ {status_id}: {e}")
            # å¼‚å¸¸ä¿æŠ¤ï¼šå¦‚æœæ ‡ç­¾é¡µæ²¡å…³æ‰ï¼Œå¼ºåˆ¶å…³é—­
            if self.driver.tabs_count > 1:
                # ç®€å•åˆ¤æ–­ä¸€ä¸‹å½“å‰é¡µæ˜¯ä¸æ˜¯åˆ—è¡¨é¡µï¼Œå¦‚æœä¸æ˜¯å°±å…³æ‰
                if str(uid) not in self.driver.latest_tab.url:
                    self.driver.latest_tab.close()
            return None
        
    def step3_batch_mine(self):
        pending = self.db.get_pending_tasks("Target_users", limit=config.PIPELINE_BATCH_SIZE)
        if not pending: return

        print(f"\n=== Step 3: çˆ¬å–è¯„è®º (æ‰¹æ¬¡: {len(pending)} äºº) ===")
        
        # è·å–å½“å‰çš„åˆ—è¡¨é¡µ Tab å¯¹è±¡
        list_tab = self.driver.latest_tab
        
        for row in pending:
            uid, uname = row['User_Id'], row['User_Name']
            ai_left = self.db.get_unanalyzed_count()
            print(f"    User: {uname} | AIå¾…åŠ: {ai_left}")
            
            self.safe_action()
            try:
                target_api = 'user_timeline.json'
                list_tab.listen.start(target_api)
                
                list_tab.get(f"https://xueqiu.com/u/{uid}")
                
                # ç­‰å¾…ç¬¬ä¸€é¡µ
                res = list_tab.listen.wait(timeout=5)
                
                total_added = 0 
                
                # --- å®šä¹‰å†…éƒ¨å‡½æ•°ï¼šç»Ÿä¸€å¤„ç†æ¯ä¸€é¡µçš„æ•°æ®è§£æé€»è¾‘ ---
                # è¿™æ ·ç¬¬ä¸€é¡µå’Œç¿»é¡µåçš„ä»£ç ä¸ç”¨å†™ä¸¤é
                def process_page_data(response_data):
                    rows = []
                    if response_data and 'statuses' in response_data:
                        for s in response_data['statuses']:
                            readable_time = self._format_time(s['created_at'])
                            
                            # === 1. å°è¯•è·å–æ™®é€šå†…å®¹ ===
                            content = s.get('text', '')
                            if not content: 
                                content = s.get('description', '')
                            
                            # === 2. ã€æ ¸å¿ƒæ–°å¢é€»è¾‘ã€‘æ£€æµ‹é•¿æ–‡å¹¶è¡¥å…¨ ===
                            # å¦‚æœ type æ˜¯ 1 æˆ– 3ï¼Œè¯´æ˜æ˜¯é•¿æ–‡/ä¸“æ ï¼Œå¿…é¡»è¿›å»æŠ“
                            # æˆ–è€… content åªæœ‰ "..." ç»“å°¾çš„æˆªæ–­å†…å®¹ï¼Œä¹Ÿå¯ä»¥å°è¯•æŠ“ä¸€ä¸‹
                            post_type = str(s.get('type', '0'))
                            
                            if post_type in ['1', '3']:
                                # è°ƒç”¨ä¸Šé¢çš„ _mine_long_articles æ–¹æ³•
                                # print(f"    æ£€æµ‹åˆ°é•¿æ–‡(type={post_type})ï¼Œæ­£åœ¨è¡¥å…¨...")
                                full_text = self._mine_long_articles(uid, s['id'])
                                if full_text:
                                    content = full_text # ç”¨æŠ“åˆ°çš„å®Œæ•´é•¿æ–‡è¦†ç›–æˆªæ–­å†…å®¹
                            
                            rows.append((
                                s['id'], 
                                s['user_id'], 
                                content, 
                                readable_time, 
                                str(s.get('stockCorrelation','')), 
                                0, 
                                s.get('retweet_count', 0), 
                                s.get('reply_count', 0), 
                                s.get('like_count', 0)
                            ))
                    return rows

                # --- å¤„ç†ç¬¬ä¸€é¡µ ---
                data = self._decode_response(res)
                if data:
                    raw_rows = process_page_data(data)
                    if raw_rows:
                        self.db.execute_many_safe("INSERT OR IGNORE INTO Raw_Statuses (Status_Id, User_Id, Description, Created_At, Stock_Tags, Is_Analyzed, Forward, Comment_Count, Like) VALUES (?,?,?,?,?,?,?,?,?)", raw_rows)
                        total_added += len(raw_rows)
                else:
                    if not res: print(f"    âš ï¸ ç¬¬ä¸€é¡µè¶…æ—¶æˆ–æ— æ•°æ®")

                # --- å¾ªç¯ç¿»é¡µç›´åˆ°è¾¾æ ‡ ---
                while total_added < config.ARTICLE_COUNT_LIMIT:
                    if self._has_slider(): self.safe_action()
                    
                    next_btn = list_tab.ele('.pagination__next', timeout=2)
                    if next_btn and next_btn.states.is_displayed: 
                        next_btn.click(by_js=True)
                        
                        # ç­‰å¾…ä¸‹ä¸€é¡µæ•°æ®åŒ…
                        res = list_tab.listen.wait(timeout=5)
                        data = self._decode_response(res)
                        
                        if data:
                            raw_rows = process_page_data(data)
                            if raw_rows:
                                self.db.execute_many_safe("INSERT OR IGNORE INTO Raw_Statuses (Status_Id, User_Id, Description, Created_At, Stock_Tags, Is_Analyzed, Forward, Comment_Count, Like) VALUES (?,?,?,?,?,?,?,?,?)", raw_rows)
                                total_added += len(raw_rows)
                            else:
                                break # æœ‰åŒ…ä½†æ²¡æ•°æ®ï¼Œå¯èƒ½åˆ°åº•äº†
                        else:
                            break # æ²¡åŒ…
                    else: 
                        break # æ²¡æŒ‰é’®äº†
                
                list_tab.listen.stop()
                print(f"    -> å®Œæˆ: {uname} (å…¥åº“: {total_added})")
                self.db.update_task_status(uid, "Target_users")
                
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸ [{uname}]: {e}")
                if "æ–­å¼€" in str(e) or "disconnected" in str(e): 
                    self._restart_browser(); list_tab = self.driver.latest_tab
                else: 
                    list_tab.listen.stop()

    # --- æ–°å¢çš„è¾…åŠ©æ–¹æ³•ï¼ˆæ”¾åœ¨ç±»å†…ï¼‰---
    def _decode_response(self, res):
        """ä»ç›‘å¬å“åº”ä¸­å®‰å…¨è§£æ JSON æ•°æ®ï¼ˆè‡ªåŠ¨å¤„ç† gzip å’Œè‡ªåŠ¨è§£æï¼‰"""
        if not res or not hasattr(res.response, 'body') or res.response.body is None:
            print("error: no res or no res body")
            return None

        body = res.response.body

        # æƒ…å†µ1: DrissionPage å·²è‡ªåŠ¨è§£æä¸º dict/listï¼ˆæ–°ç‰ˆè¡Œä¸ºï¼‰
        if isinstance(body, (dict, list)):
            return body

        # æƒ…å†µ2: æ˜¯å­—ç¬¦ä¸²ï¼ˆæ˜æ–‡ JSONï¼‰
        if isinstance(body, str):
            try:
                return json.loads(body)
            except Exception as e:
                print(f"Failed to parse string body as JSON: {e}")
                return None

        # æƒ…å†µ3: æ˜¯ bytesï¼ˆå¯èƒ½æ˜¯ gzip å‹ç¼©æˆ–åŸå§‹ JSON å­—èŠ‚ï¼‰
        if isinstance(body, bytes):
            try:
                headers = res.response.headers or {}
                # æ£€æŸ¥æ˜¯å¦ gzip å‹ç¼©
                if 'content-encoding' in headers and 'gzip' in headers['content-encoding'].lower():
                    body = gzip.decompress(body)
                # ç°åœ¨ body åº”è¯¥æ˜¯ JSON å­—ç¬¦ä¸²çš„ bytes
                text = body.decode('utf-8')
                return json.loads(text)
            except Exception as e:
                print(f"Failed to decompress or parse bytes body: {e}")
                return None

        # å…¶ä»–ç±»å‹ï¼ˆå¦‚ None, int ç­‰ï¼‰
        print(f"Unexpected body type: {type(body)}")
        return None
        
    def run(self):
        print(">>> å¯åŠ¨...")
        ai_thread = threading.Thread(target=self.global_ai_worker, daemon=False)
        ai_thread.start()
        
        self.driver.get("https://xueqiu.com")
        print("\n" + "="*50); input(">>> è¯·æ‰«ç ç™»å½•ï¼Œå®ŒæˆåæŒ‰ã€å›è½¦ã€‘..."); print("="*50 + "\n")
        
        try:
            while True:
                current_targets = self.db.get_target_count()
                if current_targets >= config.TARGET_GOAL:
                    print("\n>>> ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼ç›®æ ‡ç”¨æˆ·æ”¶é›†å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰"); break 
                
                current_users = self.db.get_total_users_count()
                ai_backlog = self.db.get_unanalyzed_count()
                print(f"\n>>> [å¾ªç¯] ç›®æ ‡:{current_targets}/{config.TARGET_GOAL} | ç”¨æˆ·åº“:{current_users}/{config.FOCUS_COUNT_LIMIT} | AIç§¯å‹:{ai_backlog}")
                
                self.step3_batch_mine()   
                self.step2_batch_filter() 
                self.step1_batch_scan()   
                time.sleep(2)

        except KeyboardInterrupt: print("\n\n>>> ğŸ›‘ æ£€æµ‹åˆ°ç”¨æˆ·ä¸­æ–­ (Ctrl+C)...")
        except Exception as e: print(f"\n\n>>> âŒ å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
        finally:
            self.is_main_job_finished = True
            left = self.db.get_unanalyzed_count()
            while left > 0:
                print(f">>> æç¤º: AI çº¿ç¨‹è¿˜åœ¨å¤„ç†å‰©ä½™çš„ {left} æ¡æ•°æ®...")
                print(">>> ç­‰å¾… AI å¤„ç†å®Œæˆ...")
                ai_thread.join(timeout=20)  # æœ€å¤šç­‰ 1 å°æ—¶ï¼Œé˜²æ­¢å¡æ­»
                left = self.db.get_unanalyzed_count()
            print(">>> ç¨‹åºå®‰å…¨é€€å‡º")

if __name__ == '__main__':
    bot = XueqiuSpider()
    bot.run()